{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['distance_from_home', 'distance_from_last_transaction', 'ratio_to_median_purchase_price',\n",
    "            'repeat_retailer', 'used_chip', 'used_pin_number', 'online_order']\n",
    "\n",
    "target = 'fraud'\n",
    "\n",
    "X = fraud[features]\n",
    "y = fraud[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1 \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='fraud', data=fraud)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud\n",
      "0.0    0.912597\n",
      "1.0    0.087403\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(fraud['fraud'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182519\n",
      "         1.0       0.58      0.95      0.72     17481\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming X and y are your features and target\n",
    "\n",
    "# Split data with stratification to keep class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize Logistic Regression with balanced class weights\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "highly imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182519\n",
      "         1.0       0.58      0.95      0.72     17481\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the model says “fraud,” it’s correct 58% of the time.\n",
    "\n",
    "Model catches  95% of actual fraud cases.\n",
    "\n",
    "F1-score balances precision and recall to 72% for fraud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_subset = fraud[[\n",
    "    'distance_from_home',\n",
    "    'distance_from_last_transaction',\n",
    "    'ratio_to_median_purchase_price',\n",
    "    'repeat_retailer',\n",
    "    'used_chip',\n",
    "    'used_pin_number',\n",
    "    'online_order',\n",
    "    'fraud'\n",
    "]]\n",
    "\n",
    "fraud_0 = fraud_subset[fraud_subset['fraud'] == 0]  \n",
    "fraud_1 = fraud_subset[fraud_subset['fraud'] == 1] \n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "fraud_1_oversampled = resample(\n",
    "    fraud_1,\n",
    "    replace=True,\n",
    "    n_samples=len(fraud_0),  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fraud_balanced = pd.concat([fraud_0, fraud_1_oversampled])\n",
    "fraud_balanced = fraud_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "X = fraud_balanced.drop('fraud', axis=1)\n",
    "y = fraud_balanced['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95928\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    182519\n",
      "         1.0       0.90      0.60      0.72     17481\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.93      0.80      0.85    200000\n",
      "weighted avg       0.96      0.96      0.96    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 3. Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict on test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "fraud_0_downsampled = resample(\n",
    "    fraud_0,\n",
    "    replace=False,               \n",
    "    n_samples=len(fraud_1),      \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fraud_balanced = pd.concat([fraud_0_downsampled, fraud_1])\n",
    "\n",
    "fraud_balanced = fraud_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95928\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    182519\n",
      "         1.0       0.90      0.60      0.72     17481\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.93      0.80      0.85    200000\n",
      "weighted avg       0.96      0.96      0.96    200000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# 3. Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict on test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# 5. Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling: fraud\n",
      "1.0    730078\n",
      "0.0    730077\n",
      "Name: count, dtype: int64\n",
      "After oversampling: fraud\n",
      "0.0    730078\n",
      "1.0    730078\n",
      "Name: count, dtype: int64\n",
      "Oversampling Results:\n",
      "Accuracy: 0.9411076624689416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94    182520\n",
      "         1.0       0.93      0.95      0.94    182519\n",
      "\n",
      "    accuracy                           0.94    365039\n",
      "   macro avg       0.94      0.94      0.94    365039\n",
      "weighted avg       0.94      0.94      0.94    365039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Oversample minority class in training set\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before oversampling:\", y_train.value_counts())\n",
    "print(\"After oversampling:\", y_train_ros.value_counts())\n",
    "\n",
    "# Train logistic regression on oversampled data\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train_ros, y_train_ros)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_ros = logreg.predict(X_test)\n",
    "print(\"Oversampling Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ros))\n",
    "print(classification_report(y_test, y_pred_ros))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before undersampling: fraud\n",
      "1.0    730078\n",
      "0.0    730077\n",
      "Name: count, dtype: int64\n",
      "After undersampling: fraud\n",
      "0.0    730077\n",
      "1.0    730077\n",
      "Name: count, dtype: int64\n",
      "Undersampling Results:\n",
      "Accuracy: 0.9411049230356209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94    182520\n",
      "         1.0       0.93      0.95      0.94    182519\n",
      "\n",
      "    accuracy                           0.94    365039\n",
      "   macro avg       0.94      0.94      0.94    365039\n",
      "weighted avg       0.94      0.94      0.94    365039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Undersample majority class in training set\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before undersampling:\", y_train.value_counts())\n",
    "print(\"After undersampling:\", y_train_rus.value_counts())\n",
    "\n",
    "# Train logistic regression on undersampled data\n",
    "logreg.fit(X_train_rus, y_train_rus)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_rus = logreg.predict(X_test)\n",
    "print(\"Undersampling Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rus))\n",
    "print(classification_report(y_test, y_pred_rus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: fraud\n",
      "1.0    730078\n",
      "0.0    730077\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: fraud\n",
      "0.0    730078\n",
      "1.0    730078\n",
      "Name: count, dtype: int64\n",
      "SMOTE Results:\n",
      "Accuracy: 0.9410967047356584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.93      0.94    182520\n",
      "         1.0       0.93      0.95      0.94    182519\n",
      "\n",
      "    accuracy                           0.94    365039\n",
      "   macro avg       0.94      0.94      0.94    365039\n",
      "weighted avg       0.94      0.94      0.94    365039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"After SMOTE:\", y_train_smote.value_counts())\n",
    "\n",
    "# Train logistic regression on SMOTE data\n",
    "logreg.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_smote = logreg.predict(X_test)\n",
    "print(\"SMOTE Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_smote))\n",
    "print(classification_report(y_test, y_pred_smote))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
